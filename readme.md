
# WebScrap

## Description

**WebScrap** est un projet de web scraping conçu pour extraire et analyser des données à partir de plusieurs sites web. Ce projet utilise Python et ses bibliothèques associées (Selenium, bs4, lxml...) pour effectuer des tâches de scraping de manière efficace et structurée.

## Table des matières

- [Installation](#installation)
- [Utilisation](#utilisation)
- [Fonctionnalités](#fonctionnalités)

## Installation

Pour installer et exécuter ce projet localement, suivez les étapes suivantes :

1. Clonez le dépôt :

   ```bash
   git clone https://github.com/othmaneirl/WebScrap.git
   ```

2. Accédez au répertoire du projet :

   ```bash
   cd WebScrap
   ```

3. Créez un environnement virtuel :

   ```bash
   python -m venv env
   ```

4. Activez l'environnement virtuel :

   - Sous Windows :

     ```bash
     .\env\Scripts\activate
     ```

   - Sous macOS/Linux :

     ```bash
     source env/bin/activate
     ```

5. Installez les dépendances nécessaires :

   ```bash
   pip install -r requirements.txt
   ```

## Utilisation

Pour utiliser le scraper, suivez les instructions disponible pour chaque site dans "instructions.txt"

Assurez-vous de configurer les paramètres de scraping dans le fichier de configuration avant de lancer le script.

## Fonctionnalités

- **Extraction de données** : Extraction de données à partir de sites web spécifiés.
- **Analyse des données** : Analyse et structuration des données extraites.
- **Exportation des données** : Exportation des données dans divers formats (csv, xlsx, etc.).

